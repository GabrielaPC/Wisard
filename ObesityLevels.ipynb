{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Estimation of Obesity Levels Based On Eating Habits and Physical Condition](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Alvo  | Valores |\n",
    "| ------------- | ------------- |\n",
    "|NObeyesdad| {Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II, Obesity Type III}| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Features  | Tipo |\n",
    "| ------------- | ------------- |\n",
    "|Gender|Categorical|\n",
    "|Age|Continuous|\n",
    "|Height|Continuous|\n",
    "|Weight|Continuous|\n",
    "|family_history_with_overweight|Binary|\n",
    "|FAVC|Binary|\n",
    "|FCVC|Integer|\n",
    "|NCP|Continuous|\n",
    "|CAEC|Categorical|\n",
    "|SMOKE|Binary|\n",
    "|CH2O|Continuous|\n",
    "|SCC|Binary|\n",
    "|FAF|Continuous|\n",
    "|TUE|Integer|\n",
    "|CALC|Categorical|\n",
    "|MTRANS|Categorical|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalação das dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "dataset = fetch_ucirepo(id=544) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = dataset.data.features \n",
    "Y = dataset.data.targets \n",
    "\n",
    "# Transform labels to int\n",
    "target_class = 'NObeyesdad'\n",
    "\n",
    "labels = Y[target_class].unique()\n",
    "for i in range(len(labels)):\n",
    "  Y.loc[Y[target_class]==labels[i], target_class] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "num_features = []\n",
    "for feature in dataset.data.features:\n",
    "    feature_info = dataset.variables.loc[dataset.variables[\"name\"] == feature]\n",
    "    if feature_info.type.values[0] == \"Categorical\":\n",
    "        cat_features.append(feature)\n",
    "    else:\n",
    "        if feature_info.type.values[0] == \"Binary\":\n",
    "            values = X[feature].unique()\n",
    "            for i in range(len(values)):\n",
    "                X.loc[X[feature]==values[i], feature] = 2*i -1\n",
    "\n",
    "        X[feature] = X[feature].astype(float) # Transforma em float caso seja str\n",
    "        num_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X,columns=cat_features, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os conjuntos de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size= 0.3, random_state = 28)\n",
    "y_true = list(y_test[target_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termômetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thermometer import Thermometer\n",
    "\n",
    "num_bits = 10\n",
    "\n",
    "term = Thermometer(x_train,num_bits) # Termometro para dados de treinamento\n",
    "term.encode(num_features)\n",
    "\n",
    "term = Thermometer(x_test,num_bits) # Termometro para dados de test\n",
    "term.encode(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wisard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wisard import Wisard\n",
    "\n",
    "wisard = Wisard(num_classes=len(labels),n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisard.train(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 2, 5, 0, 2, 5, 6, 1, 5, 3, 6, 0, 5, 6, 0, 2, 4, 6, 0, 0, 1, 3, 0, 3, 4, 3, 5, 5, 6, 4, 4, 5, 2, 1, 2, 1, 0, 2, 3, 0, 1, 5, 4, 0, 1, 1, 3, 1, 5, 6, 0, 1, 4, 0, 6, 4, 3, 1, 0, 2, 1, 0, 6, 1, 3, 0, 0, 1, 0, 6, 0, 1, 1, 2, 5, 0, 1, 2, 4, 4, 1, 1, 3, 1, 1, 3, 1, 3, 6, 1, 4, 4, 6, 1, 3, 4, 3, 1, 5, 4, 1, 1, 1, 5, 0, 1, 6, 3, 3, 4, 3, 0, 1, 0, 0, 0, 5, 3, 5, 5, 6, 0, 1, 0, 6, 4, 2, 5, 4, 5, 6, 2, 4, 5, 1, 2, 5, 6, 3, 5, 2, 3, 4, 4, 5, 1, 6, 1, 0, 1, 1, 0, 6, 5, 2, 1, 5, 3, 1, 5, 1, 4, 0, 0, 2, 4, 0, 6, 6, 3, 1, 2, 6, 5, 0, 4, 0, 3, 4, 0, 6, 2, 1, 6, 2, 0, 0, 6, 6, 0, 0, 1, 1, 1, 5, 6, 0, 5, 1, 3, 0, 0, 3, 1, 1, 0, 0, 3, 5, 5, 6, 0, 1, 0, 5, 1, 3, 3, 6, 2, 0, 1, 3, 2, 6, 0, 6, 3, 2, 3, 3, 5, 4, 3, 6, 5, 3, 3, 6, 4, 0, 1, 0, 5, 1, 3, 6, 0, 5, 4, 6, 3, 2, 5, 4, 6, 6, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 2, 3, 4, 0, 2, 5, 0, 6, 0, 5, 4, 1, 6, 0, 4, 5, 0, 3, 2, 6, 0, 0, 6, 3, 0, 1, 0, 0, 3, 1, 2, 0, 1, 0, 2, 5, 0, 3, 5, 2, 6, 3, 1, 2, 3, 0, 5, 5, 2, 0, 6, 0, 1, 6, 2, 0, 2, 2, 3, 2, 5, 6, 2, 3, 2, 3, 2, 1, 2, 6, 3, 6, 2, 6, 1, 4, 1, 5, 6, 5, 0, 1, 0, 4, 2, 3, 5, 3, 1, 5, 0, 0, 0, 1, 5, 3, 0, 1, 4, 3, 2, 0, 6, 5, 3, 4, 0, 6, 0, 4, 5, 1, 5, 5, 6, 1, 6, 5, 2, 2, 2, 1, 5, 5, 3, 5, 3, 0, 4, 3, 5, 0, 2, 2, 2, 1, 3, 5, 1, 1, 4, 6, 4, 2, 1, 1, 0, 2, 6, 4, 0, 3, 0, 4, 5, 0, 1, 0, 1, 1, 6, 2, 0, 4, 6, 1, 4, 5, 6, 0, 1, 6, 0, 0, 6, 1, 2, 4, 6, 1, 3, 0, 0, 2, 0, 5, 3, 0, 2, 6, 1, 0, 3, 0, 2, 1, 6, 4, 0, 3, 3, 3, 1, 1, 6, 0, 6, 1, 6, 5, 0, 0, 0, 0, 3, 5, 6, 6, 6, 0, 0, 6, 4, 5, 1, 0, 0, 4, 4, 3, 6, 1, 1, 2, 1, 0, 1, 4, 0, 4, 0, 0, 4, 2, 6, 0, 1, 5, 3, 5, 4, 0, 0, 3, 2, 1, 1, 1, 4, 4, 2, 1, 0, 2, 0, 5, 4, 2, 2, 0, 2, 1, 0, 6, 3, 1, 0, 3, 1, 3, 6, 3, 1, 0, 0, 5, 1, 0, 5, 2, 0, 1, 3, 6, 1, 1, 6, 4, 2, 2, 0, 4, 5, 1, 5, 3, 3, 1, 4, 1, 2, 3, 5, 0, 2, 4, 2, 1, 2, 4, 3, 0, 0, 0, 1, 3, 3, 3, 0, 5, 3, 5, 0, 1, 0, 6, 1, 1, 2, 1, 6, 3, 2, 1, 0, 1, 3, 6, 4, 6, 2, 4, 5, 3, 2, 5, 1, 2, 6, 1, 3, 3, 3, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = wisard.classify(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida: 74.13%\n",
      "Precisão obtida: 77.55%\n",
      "Recall obtido: 75.25%\n",
      "F1 Score obtida: 75.05%\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia obtida: {accuracy_score(y_true, predictions) * 100:.2f}%')\n",
    "print(f'Precisão obtida: {precision_score(y_true, predictions, average=\"macro\", zero_division=np.nan) * 100:.2f}%')\n",
    "print(f'Recall obtido: {recall_score(y_true, predictions, average=\"macro\") * 100:.2f}%')\n",
    "print(f'F1 Score obtida: {f1_score(y_true, predictions, average=\"macro\") * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
